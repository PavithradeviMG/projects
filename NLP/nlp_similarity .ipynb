{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f529e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51162fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('en_core_web_md')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deda6df",
   "metadata": {},
   "source": [
    "the difference between _md, _sm is in _sm the size of the trained pipeline is 12MB but _md is 40MB.the vector in _sm  0 keys, 0 unique vectors (0 dimensions) but in _md vector 514k keys, 20k unique vectors (300 dimensions). in _sm using context-sensitive tensors,but in _md using word vector \n",
    "Word vectors are stored in a big table in the model and when you look up cat, you always get the same vector from this table.\n",
    "\n",
    "The context-sensitive tensors are dense feature vectors computed by the models in the pipeline while analyzing the text. You will get different vectors for cat in different texts. If you use en_core_web_sm, the token cat in I have a cat will not have the same vector as in The cat is black. Having the context-sensitive tensors available when the model doesn't include word vectors lets the similarity functions work to some degree, but the results are very different than with word vectors.(source:Stackoverflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9790476",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = [ 'We bought a house in  CA. Our mortgage was handled by a company called ki. Soon after the mortgage was sold to ABC. Shortly after that XYZ took over the mortgage. The other day we got a notice not to send our payment to them but to loi instead. This is all so frustrating and wreaks of the  mortgage nightmare.',\n",
    "'I got approved for a loan to buy a house I have submitted everything I need to for them I paid for the inspection and paid good faith check after all of that they said I did not get approved for the loan to cancel my contract because they do not want to wait for the down payments assistant said that the Sellers do not want to wait that long I feel like they are getting over on me I feel that they should have told me that I did not get approved before I spent my money and picked out a house Carrington mortgage in Ohio ',\n",
    "'As per the correspondence, I received from : The University  This is to inform you that I have recently pulled my credit report and noticed that there is a collection listing from The University  on my credit report. I WAS never notified of this collection action or that I owed the debt. This letter is to inform you that I would like a verification of the debt and juilo ability to collect this money from me.',\n",
    "'I am writing to dispute the follow information in my file.ON BOTH TransUnion & . for {$15000.00}. I have contacted this agency to advise to STOP CALLING ME this case was dismissed in court  2014. Please see the attached document from  County State Court. Thanking you in advanced regarding this matter.',\n",
    "'I have not had a XXXX phone since early 2007. I have tried to resolve my bill in the past but it keeps reposting an old bill. I have no way to provide financial info from 8 years ago and they know that so they want me to prove it to them but I have no way to do that. Is there anyway to get  to find out how old it is.',\n",
    "'I posted dated a check and mailed it for 2015 for my mortgage payment as my mortgage company will only take online payments if all the late charges are paid at once ( also illegal ), and the check was cashed on 2015 which cost me over {$70.00} in over draft fees with my bank.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa7c1a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Complaints Similarity--------------------\n",
      "1.0\n",
      "0.5181293163334554\n",
      "0.7174057815665636\n",
      "0.7698360550997334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgpav\\AppData\\Local\\Temp\\ipykernel_21960\\163597993.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(token.similarity(token_))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6591949204174755\n",
      "0.6330322519005374\n",
      "0.5181293163334554\n",
      "1.0\n",
      "0.6737944189370757\n",
      "0.44519007143538514\n",
      "0.6772693041352273\n",
      "0.5799084246024038\n",
      "0.7174057815665636\n",
      "0.6737944189370757\n",
      "1.0\n",
      "0.6654231850964974\n",
      "0.6732007763894544\n",
      "0.6399289079215221\n",
      "0.7698360550997334\n",
      "0.44519007143538514\n",
      "0.6654231850964974\n",
      "1.0\n",
      "0.5691884798014691\n",
      "0.6025169096487083\n",
      "0.6591949204174755\n",
      "0.6772693041352273\n",
      "0.6732007763894544\n",
      "0.5691884798014691\n",
      "1.0\n",
      "0.46995670733457057\n",
      "0.6330322519005374\n",
      "0.5799084246024038\n",
      "0.6399289079215221\n",
      "0.6025169096487083\n",
      "0.46995670733457057\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# compare the similarity in the complain using nlp\n",
    "print(\"------------------Complaints Similarity--------------------\")\n",
    "for token in complaints:\n",
    "    token = nlp(token)\n",
    "    for token_ in complaints:\n",
    "        token_ = nlp(token_)\n",
    "        print(token.similarity(token_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f90ddc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes= [ 'Bake in the preheated oven, stirring every 20 minutes, until sugar mixture has baked and caramelized onto popcorn and cashews, about 1 hour. Spread cashew caramel corn onto a parchment paper-lined baking sheet to cool. If desired, form into balls while still warm.',\n",
    "'Combine brown sugar, corn syrup, butter, salt, and cream of tartar in a large saucepan. Bring to a boil, stirring constantly, until a candy thermometer inserted into the middle of the syrup, not touching the bottom, reads 260 degrees F (127 degrees C), 6 to 8 minutes.',\n",
    "'Lift marshmallow fudge out of the pan by the edges of the foil and place on a large cutting board. Dip a large knife in the remaining confectioners\\' sugar and slice fudge into 1 1/2-inch squares, continually dipping knife in the sugar after each slice.',\n",
    "'Melt butter in a medium saucepan over medium heat; stir in condensed milk. Pour in chocolate chips; cook and stir until melted, 5 to 10 minutes.',\n",
    "'Lightly grease a cookie sheet. Deflate the dough and turn it out onto a lightly floured surface. Roll the marzipan into a rope and place it in the center of the dough. Fold the dough over to cover it; pinch the seams together to seal. Place the loaf, seam side down, on the prepared baking sheet. Cover with a damp cloth and let rise until doubled in volume, about 40 minutes. Meanwhile, preheat oven to 350 degrees F (175 degrees C)',\n",
    "'In a large bowl, cream together the butter, brown sugar, and white sugar. Beat in the instant pudding mix until blended. Stir in the eggs and vanilla. Blend in the flour mixture. Finally, stir in the chocolate chips and nuts. Drop cookies by rounded spoonfuls onto ungreased cookie sheets.'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69587cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------recipes Similarity--------------------\n",
      "1.0\n",
      "0.694187061514351\n",
      "0.5810681312467394\n",
      "0.7831207150610254\n",
      "0.7158293113068108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgpav\\AppData\\Local\\Temp\\ipykernel_21960\\2288123392.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(token.similarity(token_))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655395965465583\n",
      "0.694187061514351\n",
      "1.0\n",
      "0.7292983580571762\n",
      "0.6922875793049557\n",
      "0.6848676852080049\n",
      "0.6753270356792216\n",
      "0.5810681312467394\n",
      "0.7292983580571762\n",
      "1.0\n",
      "0.6040473529583174\n",
      "0.6870433996007678\n",
      "0.727922680499784\n",
      "0.7831207150610254\n",
      "0.6922875793049557\n",
      "0.6040473529583174\n",
      "1.0\n",
      "0.7286112426504916\n",
      "0.6861022639785279\n",
      "0.7158293113068108\n",
      "0.6848676852080049\n",
      "0.6870433996007678\n",
      "0.7286112426504916\n",
      "1.0\n",
      "0.7674540077010704\n",
      "0.655395965465583\n",
      "0.6753270356792216\n",
      "0.727922680499784\n",
      "0.6861022639785279\n",
      "0.7674540077010704\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# compare the similarity in the recipes using nlp\n",
    "print(\"------------------recipes Similarity--------------------\")\n",
    "for token in recipes:\n",
    "    token = nlp(token)\n",
    "    for token_ in recipes:\n",
    "        token_ = nlp(token_)\n",
    "        print(token.similarity(token_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b490f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Complaints&recipes Similarity--------------------\n",
      "0.5513361206301078\n",
      "0.3351174771853903\n",
      "0.41689611614324495\n",
      "0.6338378117120104\n",
      "0.36724214233722574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgpav\\AppData\\Local\\Temp\\ipykernel_21960\\2391640167.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(token.similarity(token_))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6037979192703137\n",
      "0.42097681025141226\n",
      "0.1434038304120464\n",
      "0.4036027994810062\n",
      "0.5562153069455517\n",
      "0.18598151403824487\n",
      "0.527208106804108\n",
      "0.5599700599785095\n",
      "0.25913013906990046\n",
      "0.4909765154817415\n",
      "0.6101887719983532\n",
      "0.28033522308076153\n",
      "0.5525952040656714\n",
      "0.46019529929268094\n",
      "0.220540324190437\n",
      "0.36536234212581636\n",
      "0.581582716653889\n",
      "0.34659805085395784\n",
      "0.5066581509508683\n",
      "0.6887836295422769\n",
      "0.42132077879684643\n",
      "0.6347594403383726\n",
      "0.7833612114224145\n",
      "0.5892170995435448\n",
      "0.5925175959456686\n",
      "0.6184740512866855\n",
      "0.1397216055720053\n",
      "0.42739627371053174\n",
      "0.7195851817668213\n",
      "0.36855294648807885\n",
      "0.38373034942619705\n"
     ]
    }
   ],
   "source": [
    "# compare the similarity in the complaints and recipes using nlp\n",
    "print(\"------------------Complaints&recipes Similarity--------------------\")\n",
    "for token in recipes:\n",
    "    token = nlp(token)\n",
    "    for token_ in complaints:\n",
    "        token_ = nlp(token_)\n",
    "        print(token.similarity(token_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7bd4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
