{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3566fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08fac229",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e5117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a list\n",
    "garden_path_sentences = [\"The old man boat\",\"The horse raced paced the barn fell\"]\n",
    "#print(garden_path_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "350f9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another variable\n",
    "newsentences = [\"Mary gave the child a band-aid\",\"That jill is never here hurts\",\"The cotton clothing is made of grows in Mississippi\"]\n",
    "#print(newsentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04ca5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append both \n",
    "gardenpathsentences = garden_path_sentences + newsentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c65abb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: The, POS: DET, Tag: DT, Entity: \n",
      "Token: old, POS: ADJ, Tag: JJ, Entity: \n",
      "Token: man, POS: NOUN, Tag: NN, Entity: \n",
      "Token: boat, POS: NOUN, Tag: NN, Entity: \n",
      "----\n",
      "Token: The, POS: DET, Tag: DT, Entity: \n",
      "Token: horse, POS: NOUN, Tag: NN, Entity: \n",
      "Token: raced, POS: VERB, Tag: VBD, Entity: \n",
      "Token: paced, POS: VERB, Tag: VBD, Entity: \n",
      "Token: the, POS: DET, Tag: DT, Entity: \n",
      "Token: barn, POS: NOUN, Tag: NN, Entity: \n",
      "Token: fell, POS: VERB, Tag: VBD, Entity: \n",
      "----\n",
      "Token: Mary, POS: PROPN, Tag: NNP, Entity: PERSON\n",
      "Token: gave, POS: VERB, Tag: VBD, Entity: \n",
      "Token: the, POS: DET, Tag: DT, Entity: \n",
      "Token: child, POS: NOUN, Tag: NN, Entity: \n",
      "Token: a, POS: DET, Tag: DT, Entity: \n",
      "Token: band, POS: NOUN, Tag: NN, Entity: \n",
      "Token: -, POS: PUNCT, Tag: HYPH, Entity: \n",
      "Token: aid, POS: NOUN, Tag: NN, Entity: \n",
      "----\n",
      "Token: That, POS: DET, Tag: DT, Entity: \n",
      "Token: jill, POS: NOUN, Tag: NN, Entity: \n",
      "Token: is, POS: AUX, Tag: VBZ, Entity: \n",
      "Token: never, POS: ADV, Tag: RB, Entity: \n",
      "Token: here, POS: ADV, Tag: RB, Entity: \n",
      "Token: hurts, POS: VERB, Tag: VBZ, Entity: \n",
      "----\n",
      "Token: The, POS: DET, Tag: DT, Entity: \n",
      "Token: cotton, POS: NOUN, Tag: NN, Entity: \n",
      "Token: clothing, POS: NOUN, Tag: NN, Entity: \n",
      "Token: is, POS: AUX, Tag: VBZ, Entity: \n",
      "Token: made, POS: VERB, Tag: VBN, Entity: \n",
      "Token: of, POS: ADP, Tag: IN, Entity: \n",
      "Token: grows, POS: NOUN, Tag: NNS, Entity: \n",
      "Token: in, POS: ADP, Tag: IN, Entity: \n",
      "Token: Mississippi, POS: PROPN, Tag: NNP, Entity: GPE\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "for sentence in gardenpathsentences:\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        print(f\"Token: {token.text}, POS: {token.pos_}, Tag: {token.tag_}, Entity: {token.ent_type_}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6de48cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buildings, airports, highways, bridges, etc.\n"
     ]
    }
   ],
   "source": [
    "#example named entity recognition \n",
    "print(spacy.explain(\"FAC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c47b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People, including fictional\n"
     ]
    }
   ],
   "source": [
    "#Entity 1:\n",
    "print(spacy.explain(\"PERSON\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bd135b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "#Entity 2:\n",
    "print(spacy.explain(\"GPE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b729e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity 1:\n",
    "# - Entity: PERSON (People, including fictional)\n",
    "# - Explanation: a person or organization possessing separate and distinct legal rights, such as an individual, partnership, or corporation.\n",
    "# - Sense: Yes, it makes sense as \"PERSON\". \n",
    "\n",
    "# Entity 2:\n",
    "# - Entity: \"GPE\" (Countries, cities, states.)\n",
    "# - Explanation:geographical regions defined by political and/or social groups.\n",
    "# - Sense: Yes, it makes sense as \"GPE\".\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
